{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping Actor-Critic algorithms in LunarLander-v2 environment (A2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "env = gym.make('CartPole-v0')\n",
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "probs = np.array([0.5, 0.25, 0.25])\n",
    "np.random.choice(3, p = probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "\n",
    "1. play n steps in the environment and save (state, action, next_state), default N = ?\n",
    "2. Initialize R = 0 or R = V(St)\n",
    "3. calculate loss = td_loss + policy_gradient + (entropy_loss)\n",
    "4. update params\n",
    "5. repeat\n",
    "\n",
    "\n",
    "# Programming steps:\n",
    "1. ExpSource step return discounted reward state and action, paramas = n_step, net\n",
    "2. function to transform list of experiences into batch of states actions and reward (non terminal state rewards summed with value net output)\n",
    "3. functions to calculate approriate losses\n",
    "4. take optimizer step\n",
    "5. incorporate logger into the mix\n",
    "6. try to implement experience source with multiple environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define experience source \n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from utils import Experience\n",
    "\n",
    "#PolicyExperience = namedtuple('PolicyExperience', ('state', 'action', 'reward', 'isdone'))\n",
    "\n",
    "\"\"\"\n",
    "step returns experience with n_step unroll \n",
    "\n",
    "\"\"\"\n",
    "class SamplingPolicy:\n",
    "    \n",
    "    def __init__(self, net):\n",
    "        \n",
    "        self.net = net\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        get sampled action from state\n",
    "        currently supports only single action at a time\n",
    "        \"\"\"\n",
    "        \n",
    "        logits, _ = self.net(state)\n",
    "        output_dim = logits.shape[1]\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        #print(probs)\n",
    "        return np.random.choice(output_dim, p=probs[0])\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        return self.net(state)\n",
    "\n",
    "class ExperienceSourceForPolicy:\n",
    "    \n",
    "    def __init__(self, env, n_steps, gamma = 0.99, device=\"cpu\"):\n",
    "        \n",
    "        self.env = env\n",
    "        self.state = self.env.reset()\n",
    "        \n",
    "        self.episode_reward = 0\n",
    "        self.episode_steps = 0\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        \n",
    "        self.device = device\n",
    "        self.steps_done = 0\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def step(self, policy):\n",
    "        \n",
    "        state = self.state\n",
    "        obs_tens = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        act = policy.get_action(obs_tens)\n",
    "        \n",
    "        obs, reward, isdone, _ = self.env.step(act)\n",
    "        \n",
    "        self.episode_steps +=1\n",
    "        self.episode_reward+=reward\n",
    "        \n",
    "        first_action = act\n",
    "        total_reward = reward\n",
    "        \n",
    "        if (not isdone):\n",
    "            for i in range(self.n_steps-1):\n",
    "                obs_tens = torch.FloatTensor(obs).unsqueeze(0).to(self.device)\n",
    "                act = policy.get_action(obs_tens)\n",
    "                obs, reward, isdone, _ = self.env.step(act)\n",
    "                total_reward+=(self.gamma**(i+1))*reward\n",
    "                self.episode_reward+=reward\n",
    "                self.episode_steps+=1\n",
    "                if isdone: \n",
    "                    break\n",
    "                    \n",
    "        exp = Experience(state, first_action, obs, total_reward, isdone)\n",
    "        \n",
    "        if isdone:\n",
    "            self.state=self.env.reset()\n",
    "            episode_reward = self.episode_reward\n",
    "            episode_steps = self.episode_steps\n",
    "            \n",
    "            self.episode_steps = 0\n",
    "            self.episode_reward = 0\n",
    "                \n",
    "            return exp, (episode_reward, episode_steps)\n",
    "        \n",
    "        \n",
    "        self.state = obs\n",
    "        \n",
    "        return exp, None\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25525242 0.23736769 0.25064224 0.2567377 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class A2CBasicNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_size = 256):\n",
    "        \n",
    "        super(A2CBasicNet, self).__init__()\n",
    "        self.base = nn.Sequential(nn.Linear(input_dim, hidden_size), \n",
    "                                  nn.ReLU(), nn.Linear(hidden_size, hidden_size),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_size, hidden_size),\n",
    "                                  nn.ReLU()\n",
    "                                 )\n",
    "        \n",
    "        self.policy = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                    nn.ReLU(), nn.Linear(hidden_size, output_dim)\n",
    "                                   )\n",
    "        self.value = nn.Sequential(nn.Linear(hidden_size, hidden_size),\n",
    "                                   nn.ReLU(), nn.Linear(hidden_size, 1)\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.base(input)\n",
    "        policy_logits = self.policy(x)\n",
    "        value = self.value(x)\n",
    "        return policy_logits, value\n",
    "    \n",
    "net = A2CBasicNet(8,4)\n",
    "policy = SamplingPolicy(net)\n",
    "policy.get_action(torch.randn(1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True]\n",
      "[False  True False]\n"
     ]
    }
   ],
   "source": [
    "mask = np.array([True, False, True])\n",
    "print(mask)\n",
    "print(np.logical_not(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define utils\n",
    "\n",
    "import timeit\n",
    "\n",
    "def get_batch(batch, net, n_steps, gamma=0.99):\n",
    "    \"\"\"\n",
    "    return tensors:\n",
    "    states, actions, \n",
    "    \"\"\"\n",
    "    \n",
    "    states, acts, next_states, rewards, isdones = zip(*batch)\n",
    "    states, acts, next_states, rewards, isdones = np.stack(states), np.stack(acts), np.stack(next_states), np.stack(rewards), np.stack(isdones)\n",
    "    done_mask = np.logical_not(isdones)\n",
    "    #print(acts.shape)\n",
    "    #print(done_mask.shape)\n",
    "    \n",
    "    tens = torch.FloatTensor(next_states[done_mask])\n",
    "    Q_vals = net(tens)\n",
    "    \n",
    "    rewards[done_mask] = rewards[done_mask]+Q_vals[1].data.cpu().numpy()[:,0]*(gamma**n_steps)\n",
    "    \n",
    "    \n",
    "    return torch.FloatTensor(states), torch.tensor(acts, dtype=torch.int64), torch.FloatTensor(rewards)\n",
    "\n",
    "_, acts, vals = get_batch(bb, net, n_steps=4)\n",
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "21.3\n",
      "10\n",
      "0.07700133323669434\n",
      "27.2\n",
      "20\n",
      "0.1810014247894287\n",
      "17.4\n",
      "30\n",
      "0.23799991607666016\n",
      "17.6\n",
      "40\n",
      "0.30100178718566895\n",
      "15.5\n",
      "50\n",
      "0.3549997806549072\n",
      "13.5\n",
      "60\n",
      "0.3989999294281006\n",
      "15.8\n",
      "70\n",
      "0.4530014991760254\n",
      "11.2\n",
      "80\n",
      "0.4940001964569092\n",
      "9.4\n",
      "90\n",
      "0.5259997844696045\n",
      "10.4\n",
      "100\n",
      "0.5640013217926025\n",
      "9.8\n",
      "110\n",
      "0.5980000495910645\n",
      "9.9\n",
      "120\n",
      "0.6349997520446777\n",
      "9.7\n",
      "130\n",
      "0.6689999103546143\n",
      "9.7\n",
      "140\n",
      "0.7030000686645508\n",
      "9.5\n",
      "150\n",
      "0.7359998226165771\n",
      "9.7\n",
      "160\n",
      "0.7730000019073486\n",
      "9.6\n",
      "170\n",
      "0.806999921798706\n",
      "9.7\n",
      "180\n",
      "0.8409998416900635\n",
      "9.1\n",
      "190\n",
      "0.869999885559082\n",
      "9.9\n",
      "200\n",
      "0.9049999713897705\n",
      "9.9\n",
      "210\n",
      "0.9380004405975342\n",
      "9.7\n",
      "220\n",
      "0.9719996452331543\n",
      "9.9\n",
      "230\n",
      "1.005000352859497\n",
      "10.1\n",
      "240\n",
      "1.0399999618530273\n",
      "12.9\n",
      "250\n",
      "1.0870006084442139\n",
      "14.2\n",
      "260\n",
      "1.1410002708435059\n",
      "13.4\n",
      "270\n",
      "1.1909997463226318\n",
      "14.6\n",
      "280\n",
      "1.2420017719268799\n",
      "22.1\n",
      "290\n",
      "1.324512243270874\n",
      "19.3\n",
      "300\n",
      "1.396510362625122\n",
      "12.6\n",
      "310\n",
      "1.442018985748291\n",
      "12.3\n",
      "320\n",
      "1.4850194454193115\n",
      "10.9\n",
      "330\n",
      "1.5240182876586914\n",
      "10.6\n",
      "340\n",
      "1.5640201568603516\n",
      "10.6\n",
      "350\n",
      "1.6010181903839111\n",
      "10.2\n",
      "360\n",
      "1.6370184421539307\n",
      "12.1\n",
      "370\n",
      "1.67801833152771\n",
      "10.7\n",
      "380\n",
      "1.7170202732086182\n",
      "10.2\n",
      "390\n",
      "1.7520184516906738\n",
      "11.2\n",
      "400\n",
      "1.7930197715759277\n",
      "11.3\n",
      "410\n",
      "1.8370201587677002\n",
      "11.0\n",
      "420\n",
      "1.8745312690734863\n",
      "10.2\n",
      "430\n",
      "1.9105310440063477\n",
      "10.5\n",
      "440\n",
      "1.9475312232971191\n",
      "10.6\n",
      "450\n",
      "1.9865312576293945\n",
      "11.5\n",
      "460\n",
      "2.024531126022339\n",
      "11.1\n",
      "470\n",
      "2.0615313053131104\n",
      "10.9\n",
      "480\n",
      "2.0985312461853027\n",
      "9.9\n",
      "490\n",
      "2.1325314044952393\n",
      "11.0\n",
      "500\n",
      "2.1695311069488525\n",
      "10.6\n",
      "510\n",
      "2.205531597137451\n",
      "9.7\n",
      "520\n",
      "2.2405312061309814\n",
      "10.6\n",
      "530\n",
      "2.278531074523926\n",
      "11.7\n",
      "540\n",
      "2.323530912399292\n",
      "11.4\n",
      "550\n",
      "2.370532751083374\n",
      "12.4\n",
      "560\n",
      "2.4135310649871826\n",
      "11.9\n",
      "570\n",
      "2.4535322189331055\n",
      "11.9\n",
      "580\n",
      "2.4925310611724854\n",
      "11.4\n",
      "590\n",
      "2.531532049179077\n",
      "13.6\n",
      "600\n",
      "2.5755326747894287\n",
      "12.1\n",
      "610\n",
      "2.617532968521118\n",
      "13.4\n",
      "620\n",
      "2.675532817840576\n",
      "18.0\n",
      "630\n",
      "2.7335317134857178\n",
      "17.7\n",
      "640\n",
      "2.8035330772399902\n",
      "25.2\n",
      "650\n",
      "2.886531352996826\n",
      "24.4\n",
      "660\n",
      "2.9725327491760254\n",
      "27.4\n",
      "670\n",
      "3.0715315341949463\n",
      "17.7\n",
      "680\n",
      "3.1315314769744873\n",
      "16.2\n",
      "690\n",
      "3.1915316581726074\n",
      "20.3\n",
      "700\n",
      "3.2595314979553223\n",
      "21.1\n",
      "710\n",
      "3.324531078338623\n",
      "18.7\n",
      "720\n",
      "3.3915326595306396\n",
      "20.1\n",
      "730\n",
      "3.468343734741211\n",
      "21.4\n",
      "740\n",
      "3.5405807495117188\n",
      "22.6\n",
      "750\n",
      "3.6205806732177734\n",
      "32.1\n",
      "760\n",
      "3.73358154296875\n",
      "23.7\n",
      "770\n",
      "3.822601795196533\n",
      "21.5\n",
      "780\n",
      "3.895601987838745\n",
      "19.9\n",
      "790\n",
      "3.962601661682129\n",
      "26.5\n",
      "800\n",
      "4.057601690292358\n",
      "16.4\n",
      "810\n",
      "4.1176018714904785\n",
      "22.2\n",
      "820\n",
      "4.1956024169921875\n",
      "18.5\n",
      "830\n",
      "4.253602504730225\n",
      "22.2\n",
      "840\n",
      "4.331603527069092\n",
      "17.4\n",
      "850\n",
      "4.393601655960083\n",
      "25.1\n",
      "860\n",
      "4.48760199546814\n",
      "25.5\n",
      "870\n",
      "4.579602479934692\n",
      "25.4\n",
      "880\n",
      "4.662602663040161\n",
      "18.1\n",
      "890\n",
      "4.726628303527832\n",
      "42.9\n",
      "900\n",
      "4.870660781860352\n",
      "21.2\n",
      "910\n",
      "4.94166111946106\n",
      "36.0\n",
      "920\n",
      "5.063660621643066\n",
      "24.3\n",
      "930\n",
      "5.146660804748535\n",
      "27.7\n",
      "940\n",
      "5.23866081237793\n",
      "26.5\n",
      "950\n",
      "5.327661037445068\n",
      "28.4\n",
      "960\n",
      "5.427660942077637\n",
      "24.9\n",
      "970\n",
      "5.523662328720093\n",
      "25.6\n",
      "980\n",
      "5.612660884857178\n",
      "30.9\n",
      "990\n",
      "5.71566104888916\n",
      "45.4\n",
      "1000\n",
      "5.867661476135254\n",
      "27.2\n",
      "1010\n",
      "5.960660696029663\n",
      "22.7\n",
      "1020\n",
      "6.039661645889282\n",
      "23.8\n",
      "1030\n",
      "6.12367057800293\n",
      "20.7\n",
      "1040\n",
      "6.1946702003479\n",
      "36.7\n",
      "1050\n",
      "6.3136701583862305\n",
      "35.5\n",
      "1060\n",
      "6.455672025680542\n",
      "40.2\n",
      "1070\n",
      "6.5946714878082275\n",
      "24.3\n",
      "1080\n",
      "6.683706521987915\n",
      "29.8\n",
      "1090\n",
      "6.787731647491455\n",
      "33.3\n",
      "1100\n",
      "6.9047300815582275\n",
      "30.0\n",
      "1110\n",
      "7.002730131149292\n",
      "20.3\n",
      "1120\n",
      "7.073729991912842\n",
      "21.3\n",
      "1130\n",
      "7.146729946136475\n",
      "24.7\n",
      "1140\n",
      "7.228731632232666\n",
      "23.3\n",
      "1150\n",
      "7.31173038482666\n",
      "37.5\n",
      "1160\n",
      "7.441730976104736\n",
      "40.4\n",
      "1170\n",
      "7.5897300243377686\n",
      "40.6\n",
      "1180\n",
      "7.7287304401397705\n",
      "25.3\n",
      "1190\n",
      "7.820730924606323\n",
      "22.7\n",
      "1200\n",
      "7.895730495452881\n",
      "18.0\n",
      "1210\n",
      "7.964731216430664\n",
      "43.3\n",
      "1220\n",
      "8.119730710983276\n",
      "29.9\n",
      "1230\n",
      "8.227730751037598\n",
      "29.4\n",
      "1240\n",
      "8.329731464385986\n",
      "39.4\n",
      "1250\n",
      "8.461731910705566\n",
      "65.9\n",
      "1260\n",
      "8.698730945587158\n",
      "38.3\n",
      "1270\n",
      "8.824730157852173\n",
      "56.1\n",
      "1280\n",
      "9.010730266571045\n",
      "30.6\n",
      "1290\n",
      "9.119731187820435\n",
      "33.0\n",
      "1300\n",
      "9.229730129241943\n",
      "68.2\n",
      "1310\n",
      "9.466731786727905\n",
      "88.1\n",
      "1320\n",
      "9.770730257034302\n",
      "75.6\n",
      "1330\n",
      "10.030730724334717\n",
      "100.8\n",
      "1340\n",
      "10.368731260299683\n",
      "64.7\n",
      "1350\n",
      "10.587740182876587\n",
      "40.8\n",
      "1360\n",
      "10.730741500854492\n",
      "53.8\n",
      "1370\n",
      "10.915740013122559\n",
      "62.2\n",
      "1380\n",
      "11.13374137878418\n",
      "45.7\n",
      "1390\n",
      "11.289758920669556\n",
      "25.6\n",
      "1400\n",
      "11.376757144927979\n",
      "35.6\n",
      "1410\n",
      "11.501758575439453\n",
      "35.5\n",
      "1420\n",
      "11.618757009506226\n",
      "31.8\n",
      "1430\n",
      "11.727756977081299\n",
      "38.1\n",
      "1440\n",
      "11.86175799369812\n",
      "40.2\n",
      "1450\n",
      "12.000756978988647\n",
      "45.4\n",
      "1460\n",
      "12.177758693695068\n",
      "18.5\n",
      "1470\n",
      "12.247780799865723\n",
      "25.5\n",
      "1480\n",
      "12.33481502532959\n",
      "22.7\n",
      "1490\n",
      "12.413815021514893\n",
      "28.2\n",
      "1500\n",
      "12.507814884185791\n",
      "59.6\n",
      "1510\n",
      "12.7108154296875\n",
      "57.3\n",
      "1520\n",
      "12.914849996566772\n",
      "31.5\n",
      "1530\n",
      "13.020850419998169\n",
      "24.5\n",
      "1540\n",
      "13.099850177764893\n",
      "39.4\n",
      "1550\n",
      "13.235849857330322\n",
      "71.9\n",
      "1560\n",
      "13.484357357025146\n",
      "80.2\n",
      "1570\n",
      "13.754359006881714\n",
      "29.5\n",
      "1580\n",
      "13.87135910987854\n",
      "14.4\n",
      "1590\n",
      "13.920358419418335\n",
      "13.9\n",
      "1600\n",
      "13.975357294082642\n",
      "14.8\n",
      "1610\n",
      "14.027357339859009\n",
      "13.1\n",
      "1620\n",
      "14.070357322692871\n",
      "13.8\n",
      "1630\n",
      "14.123357772827148\n",
      "16.0\n",
      "1640\n",
      "14.182358026504517\n",
      "17.6\n",
      "1650\n",
      "14.239357233047485\n",
      "17.9\n",
      "1660\n",
      "14.304357290267944\n",
      "20.4\n",
      "1670\n",
      "14.374357223510742\n",
      "21.2\n",
      "1680\n",
      "14.439357042312622\n",
      "33.6\n",
      "1690\n",
      "14.561357498168945\n",
      "48.8\n",
      "1700\n",
      "14.727357387542725\n",
      "35.5\n",
      "1710\n",
      "14.853359460830688\n",
      "38.0\n",
      "1720\n",
      "14.987384796142578\n",
      "42.7\n",
      "1730\n",
      "15.136385917663574\n",
      "40.2\n",
      "1740\n",
      "15.269384860992432\n",
      "94.7\n",
      "1750\n",
      "15.59638524055481\n",
      "73.6\n",
      "1760\n",
      "15.865384817123413\n",
      "67.5\n",
      "1770\n",
      "16.120420455932617\n",
      "34.5\n",
      "1780\n",
      "16.248420000076294\n",
      "20.1\n",
      "1790\n",
      "16.323418855667114\n",
      "34.8\n",
      "1800\n",
      "16.447418689727783\n",
      "34.5\n",
      "1810\n",
      "16.56742000579834\n",
      "61.9\n",
      "1820\n",
      "16.780418872833252\n",
      "65.6\n",
      "1830\n",
      "17.009418487548828\n",
      "64.2\n",
      "1840\n",
      "17.235673666000366\n",
      "26.0\n",
      "1850\n",
      "17.32167363166809\n",
      "19.0\n",
      "1860\n",
      "17.389673709869385\n",
      "14.2\n",
      "1870\n",
      "17.437673807144165\n",
      "15.9\n",
      "1880\n",
      "17.489673376083374\n",
      "15.6\n",
      "1890\n",
      "17.546674251556396\n",
      "15.8\n",
      "1900\n",
      "17.601675271987915\n",
      "18.8\n",
      "1910\n",
      "17.6758816242218\n",
      "13.9\n",
      "1920\n",
      "17.722883224487305\n",
      "22.5\n",
      "1930\n",
      "17.80888295173645\n",
      "20.9\n",
      "1940\n",
      "17.875881671905518\n",
      "25.8\n",
      "1950\n",
      "17.96788263320923\n",
      "36.4\n",
      "1960\n",
      "18.094881534576416\n",
      "44.5\n",
      "1970\n",
      "18.257884740829468\n",
      "53.8\n",
      "1980\n",
      "18.43788170814514\n",
      "77.1\n",
      "1990\n",
      "18.706881523132324\n",
      "85.7\n",
      "2000\n",
      "19.019389629364014\n",
      "78.9\n",
      "2010\n",
      "19.283389568328857\n",
      "78.2\n",
      "2020\n",
      "19.57038974761963\n",
      "33.1\n",
      "2030\n",
      "19.686389446258545\n",
      "44.1\n",
      "2040\n",
      "19.840391159057617\n",
      "65.1\n",
      "2050\n",
      "20.068390130996704\n",
      "65.2\n",
      "2060\n",
      "20.301389694213867\n",
      "58.6\n",
      "2070\n",
      "20.501389503479004\n",
      "129.4\n",
      "2080\n",
      "20.974900722503662\n",
      "115.2\n",
      "2090\n",
      "21.360898971557617\n",
      "101.6\n",
      "2100\n",
      "21.716319799423218\n",
      "37.5\n",
      "2110\n",
      "21.842649221420288\n",
      "92.5\n",
      "2120\n",
      "22.15567111968994\n",
      "65.8\n",
      "2130\n",
      "22.373671054840088\n",
      "26.8\n",
      "2140\n",
      "22.471672773361206\n",
      "12.5\n",
      "2150\n",
      "22.512671947479248\n",
      "13.5\n",
      "2160\n",
      "22.559672117233276\n",
      "12.8\n",
      "2170\n",
      "22.606671810150146\n",
      "13.1\n",
      "2180\n",
      "22.657673358917236\n",
      "12.7\n",
      "2190\n",
      "22.704673051834106\n",
      "13.3\n",
      "2200\n",
      "22.75067114830017\n",
      "13.8\n",
      "2210\n",
      "22.802671432495117\n",
      "15.1\n",
      "2220\n",
      "22.854671001434326\n",
      "18.3\n",
      "2230\n",
      "22.918672800064087\n",
      "59.5\n",
      "2240\n",
      "23.12967085838318\n",
      "101.6\n",
      "2250\n",
      "23.47167158126831\n",
      "51.8\n",
      "2260\n",
      "23.64467191696167\n",
      "116.7\n",
      "2270\n",
      "24.046671390533447\n",
      "162.2\n",
      "2280\n",
      "24.610695123672485\n",
      "57.7\n",
      "2290\n",
      "24.81669545173645\n",
      "79.1\n",
      "2300\n",
      "25.10769534111023\n",
      "67.1\n",
      "2310\n",
      "25.34169578552246\n",
      "69.0\n",
      "2320\n",
      "25.586695432662964\n",
      "145.0\n",
      "2330\n",
      "26.088695764541626\n",
      "162.8\n",
      "2340\n",
      "26.64869499206543\n",
      "181.8\n",
      "2350\n",
      "27.2956964969635\n",
      "198.9\n",
      "2360\n",
      "27.96472692489624\n",
      "175.2\n",
      "2370\n",
      "28.566728115081787\n",
      "46.3\n",
      "2380\n",
      "28.7397301197052\n",
      "21.6\n",
      "2390\n",
      "28.81872844696045\n",
      "24.4\n",
      "2400\n",
      "28.902729034423828\n",
      "13.6\n",
      "2410\n",
      "28.95673966407776\n",
      "16.2\n",
      "2420\n",
      "29.01573872566223\n",
      "21.6\n",
      "2430\n",
      "29.091737270355225\n",
      "20.9\n",
      "2440\n",
      "29.163759231567383\n",
      "38.1\n",
      "2450\n",
      "29.30176067352295\n",
      "33.6\n",
      "2460\n",
      "29.412760019302368\n",
      "77.9\n",
      "2470\n",
      "29.67875909805298\n",
      "146.9\n",
      "2480\n",
      "30.194761753082275\n",
      "186.2\n",
      "2490\n",
      "30.868778228759766\n",
      "200.0\n",
      "2500\n",
      "31.566779136657715\n",
      "Solved\n"
     ]
    }
   ],
   "source": [
    "# define training loop (Params From Deep Reinforcement Learning Hands-On, Maxim Lapan)\n",
    "import time\n",
    "\n",
    "gamma = 0.99\n",
    "lr = 0.001\n",
    "beta = 0.01\n",
    "batch_size = 32\n",
    "num_envs = 50\n",
    "\n",
    "reward_steps = 4\n",
    "clip_grad = 0.1\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "net = A2CBasicNet(4, 2)\n",
    "policy = SamplingPolicy(net)\n",
    "exp_source = ExperienceSourceForPolicy(env, n_steps = reward_steps)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "episode_rewards = []\n",
    "episodes_done=0\n",
    "batch = []\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"start training\")\n",
    "while True:\n",
    "    exp, rew = exp_source.step(policy)\n",
    "    batch.append(exp)\n",
    "    if rew!=None:\n",
    "        reward, steps = rew\n",
    "        episode_rewards.append(reward)\n",
    "        if len(episode_rewards)%10==0 and len(episode_rewards) > 0:\n",
    "            print(sum(episode_rewards[-10:])/10)\n",
    "            print(len(episode_rewards))\n",
    "            print(time.time()-start_time)\n",
    "            if sum(episode_rewards[-10:])/10 > 199:\n",
    "                print(\"Solved\")\n",
    "                break\n",
    "                \n",
    "    if len(batch) == batch_size:\n",
    "        states, acts, rewards = get_batch(batch, net, n_steps=reward_steps)\n",
    "        batch.clear()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, vals = net(states)\n",
    "        \n",
    "        value_loss = F.mse_loss(vals.squeeze(-1), rewards)\n",
    "        \n",
    "        log_probs = F.log_softmax(logits, dim=1)\n",
    "        adv_v = rewards-vals.detach()\n",
    "        log_p_a = log_probs[range(batch_size), acts]\n",
    "        \n",
    "        policy_loss = -(adv_v*log_p_a).mean()\n",
    "        \n",
    "        policy_loss.backward(retain_graph=True)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ent = (probs*log_probs).sum(dim=1).mean()\n",
    "        \n",
    "        entropy_loss = beta*ent\n",
    "        \n",
    "        loss = value_loss+entropy_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Handlebatching \n",
    "        #calculate policy loss\n",
    "        #calculate value loss\n",
    "        #calculate entropy loss\n",
    "\n",
    "            # update parameters\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
